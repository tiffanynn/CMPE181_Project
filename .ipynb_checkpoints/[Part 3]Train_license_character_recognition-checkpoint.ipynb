{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GxW3Qg-ScurV"
   },
   "source": [
    "#### This notebook is used to train a character recongition from input image using MobileNets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wrapt\n",
      "  Using cached wrapt-1.12.1-cp37-cp37m-win_amd64.whl\n",
      "Installing collected packages: wrapt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'c:\\\\users\\\\tiffa\\\\anaconda3\\\\Lib\\\\site-packages\\\\wrapt\\\\_wrappers.cp37-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (4.5.2.52)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from opencv-python) (1.19.5)\n",
      "Requirement already satisfied: keras in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from keras) (1.19.5)\n",
      "Requirement already satisfied: h5py in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from keras) (3.1.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from keras) (3.13)\n",
      "Requirement already satisfied: cached-property in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from h5py->keras) (1.5.2)\n",
      "Requirement already satisfied: keras.applications in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from keras.applications) (1.19.5)\n",
      "Requirement already satisfied: h5py in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from keras.applications) (3.1.0)\n",
      "Requirement already satisfied: cached-property in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from h5py->keras.applications) (1.5.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement keras.applications.MobileNetV2 (from versions: none)\n",
      "ERROR: No matching distribution found for keras.applications.MobileNetV2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.5.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.36.2)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.12.0)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.34.1)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.12)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.19.5)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.12.1)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.5.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.7.4.3)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.17.0)\n",
      "Requirement already satisfied: cached-property in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from h5py~=3.1.0->tensorflow-gpu) (1.5.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow-gpu) (0.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow-gpu) (2.21.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow-gpu) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow-gpu) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow-gpu) (56.2.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow-gpu) (0.14.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow-gpu) (1.30.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow-gpu) (0.6)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (2018.11.29)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (1.24.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\tiffa\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-gpu) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wrapt --upgrade --ignore-installed\n",
    "!pip install opencv-python\n",
    "!pip install keras\n",
    "!pip install keras.applications\n",
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "XJmrQrB_curX",
    "outputId": "5a4bee5b-8c58-41bb-cd70-ff9ffa406ff9"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MobileNetV2' from 'keras.applications' (C:\\Users\\tiffa\\Anaconda3\\lib\\site-packages\\keras\\applications\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-be677108714c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMobileNetV2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAveragePooling2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'MobileNetV2' from 'keras.applications' (C:\\Users\\tiffa\\Anaconda3\\lib\\site-packages\\keras\\applications\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# ignore warning \n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import model_from_json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z8ApWHt8curj"
   },
   "source": [
    "### Visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "-y1mnjyPcurk",
    "outputId": "de256a8f-5bb5-47c7-91c5-b29832539766",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_paths = glob.glob(\"dataset_characters/**/*.jpg\")\n",
    "\n",
    "cols=4\n",
    "rows=3\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.rcParams.update({\"font.size\":14})\n",
    "grid = gridspec.GridSpec(ncols=cols,nrows=rows,figure=fig)\n",
    "\n",
    "# create a random list of images will be displayed\n",
    "np.random.seed(45)\n",
    "rand = np.random.randint(0,len(dataset_paths),size=(cols*rows))\n",
    "\n",
    "# Plot image\n",
    "for i in range(cols*rows):\n",
    "    fig.add_subplot(grid[i])\n",
    "    image = load_img(dataset_paths[rand[i]])\n",
    "    label = dataset_paths[rand[i]].split(os.path.sep)[-2]\n",
    "    plt.title('\"{:s}\"'.format(label))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image)\n",
    "\n",
    "plt.savefig(\"Visualize_dataset.jpg\",dpi=300)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJzYBWt3bzAj"
   },
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Yh443FGFRgFP",
    "outputId": "2fdc22f4-e393-4ae1-bb86-d5fb55ed1865"
   },
   "outputs": [],
   "source": [
    "# Arange input data and corresponding labels\n",
    "X=[]\n",
    "labels=[]\n",
    "\n",
    "for image_path in dataset_paths:\n",
    "  label = image_path.split(os.path.sep)[-2]\n",
    "  image=load_img(image_path,target_size=(80,80))\n",
    "  image=img_to_array(image)\n",
    "\n",
    "  X.append(image)\n",
    "  labels.append(label)\n",
    "\n",
    "X = np.array(X,dtype=\"float16\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"[INFO] Find {:d} images with {:d} classes\".format(len(X),len(set(labels))))\n",
    "\n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "lb = LabelEncoder()\n",
    "lb.fit(labels)\n",
    "labels = lb.transform(labels)\n",
    "y = to_categorical(labels)\n",
    "\n",
    "# save label file so we can use in another script\n",
    "np.save('license_character_classes.npy', lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AOHM-oeWSsPd"
   },
   "outputs": [],
   "source": [
    "# split 10% of data as validation set\n",
    "(trainX, testX, trainY, testY) = train_test_split(X, y, test_size=0.10, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1DfUhlOTcurq"
   },
   "outputs": [],
   "source": [
    "# data augumentation\n",
    "image_gen = ImageDataGenerator(rotation_range=10,\n",
    "                              width_shift_range=0.1,\n",
    "                              height_shift_range=0.1,\n",
    "                              shear_range=0.1,\n",
    "                              zoom_range=0.1,\n",
    "                              fill_mode=\"nearest\"\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNMFc03Mb45i"
   },
   "source": [
    "## Initialize MobileNets architecture with pre-trained weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AaemgepFcur0"
   },
   "outputs": [],
   "source": [
    "# Create our model with pre-trained MobileNetV2 architecture from imagenet\n",
    "def create_model(lr=1e-4,decay=1e-4/25, training=False,output_shape=y.shape[1]):\n",
    "    baseModel = MobileNetV2(weights=\"imagenet\", \n",
    "                            include_top=False,\n",
    "                            input_tensor=Input(shape=(80, 80, 3)))\n",
    "\n",
    "    headModel = baseModel.output\n",
    "    headModel = AveragePooling2D(pool_size=(3, 3))(headModel)\n",
    "    headModel = Flatten(name=\"flatten\")(headModel)\n",
    "    headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.5)(headModel)\n",
    "    headModel = Dense(output_shape, activation=\"softmax\")(headModel)\n",
    "    \n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    \n",
    "    if training:\n",
    "        # define trainable lalyer\n",
    "        for layer in baseModel.layers:\n",
    "            layer.trainable = True\n",
    "        # compile model\n",
    "        optimizer = Adam(lr=lr, decay = decay)\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer,metrics=[\"accuracy\"])    \n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "-B5O6zG_cur5",
    "outputId": "83bfaffb-85bd-4219-da8e-ed68d7c656ad"
   },
   "outputs": [],
   "source": [
    "# initilaize initial hyperparameter\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 30\n",
    "\n",
    "model = create_model(lr=INIT_LR, decay=INIT_LR/EPOCHS,training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JR0L3nWgb-gK"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4d4NQLwDcusA",
    "outputId": "29c5fad5-3f23-427c-f04c-01af2a140e40"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "my_checkpointer = [\n",
    "                EarlyStopping(monitor='val_loss', patience=5, verbose=0),\n",
    "                ModelCheckpoint(filepath=\"License_character_recognition.h5\", verbose=1, save_weights_only=True)\n",
    "                ]\n",
    "\n",
    "result = model.fit(image_gen.flow(trainX, trainY, batch_size=BATCH_SIZE), \n",
    "                   steps_per_epoch=len(trainX) // BATCH_SIZE, \n",
    "                   validation_data=(testX, testY), \n",
    "                   validation_steps=len(testX) // BATCH_SIZE, \n",
    "                   epochs=EPOCHS, callbacks=my_checkpointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "va-WvqTpcCJw"
   },
   "source": [
    "## Visualize training result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "colab_type": "code",
    "id": "qUYOQrVzcusF",
    "outputId": "66bf8f56-e839-40bb-f1b7-3d7307c7fe26"
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(14,5))\n",
    "grid=gridspec.GridSpec(ncols=2,nrows=1,figure=fig)\n",
    "fig.add_subplot(grid[0])\n",
    "plt.plot(result.history['accuracy'], label='training accuracy')\n",
    "plt.plot(result.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(grid[1])\n",
    "plt.plot(result.history['loss'], label='training loss')\n",
    "plt.plot(result.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "\n",
    "#plt.savefig(\"Training_result.jpg\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w8JOq60Xw1UY"
   },
   "outputs": [],
   "source": [
    "# save model architectur as json file\n",
    "model_json = model.to_json()\n",
    "with open(\"MobileNets_character_recognition.json\", \"w\") as json_file:\n",
    "  json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t92Je4kBbs0g"
   },
   "source": [
    "## The End!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Train_license_character_recognition.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
